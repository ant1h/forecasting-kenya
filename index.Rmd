---
title: "Forecasting the economy of Kenya"
author: "Antoine Herlin"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,warning=FALSE)
```


This page presents a macroeconomic model I developped for the Kenyan economy with the [R language](https://www.r-project.org/). Code is available [here](https://github.com/ant1h/forecasting-kenya).

The model was estimated on Kenyan data while I did some consulting for the Kenyan National Treasury but the code could probably be easily adapted to other countries.


## Objectives of the model

The model was developed from a policy maker perspective. This means it could be used to provide insights to support choices in economic policy and public finance.

Knowing this, I think the model should fulfil 3 main objectives:

1. **Provide reliable forecasts in the short-run** (2-3 years).

2. **Provide insights about the uncertainty around forecasts.** Economic forecast are always uncertain: this can be due to data or modelling limitations but economic behaviors are anyway non-deterministic processes that have inherent uncertainty. A good policy decision framework should not only rely on a central prediction but also take into account other possible outcomes and their probabilities. It is not always easy to persuade a policy makers on the merits of this idea  but I really believe that a statement like “there is a 40% that growth will be between 2% and 4%” is much more valuable than to say “it’s going to be 3%”.

3. **Provide interpretable results.** As it is going to inform discussions on policies, it is important to explain why we ended up with a specific forecast. When estimating the model, this means that we should not only base our modelling choices on statistical fit or forecasting performance but also make sure that there are always economic soundness behind our equations.

## Quick look at the data

The main data used are the Kenya National Accounts and more specifically GDP by expenditure in constant prices (the demand side of real GDP), as demand-driven forecasting is a common approach for short-run forecasting .Data can be downloaded on the [United nation website](https://unstats.un.org/unsd/snaama/CountryProfile?ccode=404). Additional data on exchange rates, world and regional growth, oil prices, real interest rates come from other public sources like the World Bank website (see all links in the “data.R” file).

Data needs to be parsed in the two CSV files in the repository (“un_gdp_constant.csv” and "ext_data.csv"). Then we run the code from the “data.R” file to import and prepare datasets.



```{r load_data, echo = T, results = 'hide', warning=FALSE, message=FALSE}
source('utils.R') # Load required libraries and functions
source('data.R') # Load and prepare data
```

Let's plot real GDP growth since 1970 and contributions from each expenditure to growth:

```{r data_exploration}
plot(contribgdp_plot)
```

## Models estimation

Now that the data is loaded we can work on model estimation. I will estimate 3 different models that I will compare and discuss.

1. A **baseline univariate model**: just a naive univariate autoregressive model on GDP. This will be used as a benchmark for more elaborated approaches.

2. A **pure statistical model** without explicit economic assumptions. I will fit the best autoregressive model for each GDP expenditure without caring too much about economic soundness.

3. An **economic model**. Here I will try to balance statistical fit, forecasting performance with economic soundness and interpretability.


The detailed estimation processes for each model with all steps and specifications discussions can be found in the three files 'baseline_model.R', 'stat_model.R' and 'eco_model.R'.

Quicker implementations of models estimations can be found in the file 'model_functions.R'. For example, an estimation of the economic model is obtained using function *emodel* as follows:

```{r model_function, echo = T, results = 'hide', warning=FALSE, message=FALSE}
source('model_functions.R') # Load required libraries and functions
```

```{r emodel}
# Choose end of forecast year
end_pred   <- 2030 # user choice for end of forecast
window=c(min(data$Year),max(data$Year),max(data$Year)+1,end_pred)
pred_len <- (end_pred - max(data$Year))

# Uncertainty parameters
int1 <- 60 # first confidence interval  (in %)
int2 <- 95 # second confidence interval (in %)

# Estimate an economic model
eco_model <- quiet(emodel(data,exdata,window))
# Plot forecasts
autoplot(ts(eco_model[[3]]$gdp,start=window[1])) +
  geom_vline(xintercept = window[3]-1.5, color='blue') +
  annotate("text", x=window[3]+3, y=max(eco_model[[3]]$gdp), label= "Forecast", color='blue',size=5)+
  labs(title = "Real GDP growth forecast from economic model",y='Real GDP growth')
```


## Performance evaluation

So far, the specifications of our models have been chosen based on fit on historical data (with a penalization on complexity like in the AIC information criterion) and some economic sense.

To better assess the actual forecasting performances of these models, it is also important to have out-of-sample performance metrics to have an idea of how well the models would do if we were to use them in the future.

To do that we split our data into two sets. The 1st set (estimation window) will be used to estimate the models. We then forecast for the years of the 2nd set (forecasting window) to compare predictions with actual data and compute a metric to evaluate forecasting accuracy

There are many ways to perform out-of-sample evaluation (Fixed Estimation Window / Expanding Estimation Window / Rolling Estimation Window). Here, I think that we need to take into account that:
* we don't have plenty of data, so we should use as many years as possible in the estimation window
* we want our forecasting model to perform well in a 2-3 years forecasting window
* we want our forecasting model to perform well in the "current years" (rather than far in the past)

So the strategy I retain here is to estimate models on the window [1970 to Y]. Then forecast for years Y+1 to Y+3, that for Y+1 between 2007 and 2016 (Y+3 from 2009 to 2018).


We can use different metrics for accuracy:
* Bias is the difference between the forecasts and the correct outcome (on average)
* Variance shows if a narrow range of outcomes is compatible with the forecast
* Mean Squared Forecast Error (MSE) is a combination of the two, MSE = SE² + BIAS²

The choice of metric should reflect forecaster's preferences. Usually it is considered that large error are very costly so MSE is more relevant than just bias. Also note that MSE assume that forecasts errors costs are symetrics, wich is not always the case (ex: deflation often perceived as more costly than inflation).










